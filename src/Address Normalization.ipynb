{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Address Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from transform.normalizer import *\n",
    "from transform.parser import *\n",
    "from match.match import *\n",
    "import inspect\n",
    "import jellyfish\n",
    "from retrieve.search import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's read the data that we're going to use to normalize and parse the addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuation = set(string.punctuation)\n",
    "language = 'portuguese'\n",
    "\n",
    "prefix_file = '../data/prefixes.csv'\n",
    "\n",
    "with open(prefix_file, 'r') as g:\n",
    "    prefixes = g.read().splitlines()\n",
    "address_prefixes = prefixes\n",
    "\n",
    "stopw = stopwords.words(language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - `punctuation` is the file with the punctuation characters that we want to remove.\n",
    " - `prefixes` are the the common address prefixes that we want to remove.\n",
    " - `stopw` are the common Portuguese stopwords that we also want to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized address:  xv novembro 123 bloco 23\n"
     ]
    }
   ],
   "source": [
    "address = \"Rua XV de Novembro, 123 bloco 23 A\"\n",
    "\n",
    "normalized_address = normalize_address(\n",
    "    address, punctuation, stopw , address_prefixes)\n",
    "print(\"Normalized address: \", normalized_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what are we doing here? Let's see what `normalize_address` is doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['def normalize_address(input_string, punctuation, stopwords, prefixes):\\n',\n",
       "  '    pipeline = [\\n',\n",
       "  '        transform_encoding,\\n',\n",
       "  '        transform_case,\\n',\n",
       "  '        partial(remove_punctuation, punctuation=punctuation),\\n',\n",
       "  '        partial(remove_stopwords, stopwords=stopwords),\\n',\n",
       "  '        partial(remove_address_prefixes, address_prefixes=prefixes)\\n',\n",
       "  '    ]\\n',\n",
       "  '    return reduce((lambda value, func: func(value)), pipeline, input_string)\\n'],\n",
       " 41)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsourcelines(normalize_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we are doing several operations in sequence:\n",
    "\n",
    "- `transform_encoding`\n",
    "- `transform_case`\n",
    "- `remove_punctuation`\n",
    "- `remove_stopwords`\n",
    "- `remove_address_prefixes`\n",
    "\n",
    "Applying the next function to the results of the previous one. So what's next?\n",
    "\n",
    "## Parsing the address\n",
    "\n",
    "After we normalized the address we want to parse it, selecting the relevant parts. We can do that with *Regex* or *Named Entity Recognition*. First, let's try to use regular expressions: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'street': 'xv novembro', 'complement': 'bloco 23', 'number': '23124'}\n"
     ]
    }
   ],
   "source": [
    "parsed_address = parse_address(normalized_address)\n",
    "print(parsed_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how are we doing that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['def parse_address(input_string):\\n',\n",
       "  \"    matched = re.findall(r'^(\\\\S+\\\\D*?)\\\\s*(\\\\d+)|(\\\\S.*)', input_string)\\n\",\n",
       "  '    clean = list(filter(None, [e for l in matched for e in l]))\\n',\n",
       "  '    return {\\n',\n",
       "  \"        'street': clean[0],\\n\",\n",
       "  \"        'number':clean[1],\\n\",\n",
       "  \"        'complement':clean[2]\\n\",\n",
       "  '    }\\n'],\n",
       " 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsourcelines(parse_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the regular expression: **`^(\\\\S+\\\\D*?)\\\\s*(\\\\d+)|(\\\\S.*)`.**\n",
    "\n",
    "It [means](https://regex101.com/#python):\n",
    "```\n",
    "1st Alternative: ^(\\S+\\D*?)\\s*(\\d+)\n",
    "^ assert position at start of the string\n",
    "\n",
    "1st Capturing group (\\S+\\D*?)\n",
    "\\S+ match any non-white space character [^\\r\\n\\t\\f ]\n",
    "Quantifier: + Between one and unlimited times, as many times as possible, giving back as needed [greedy]\n",
    "\\D*? match any character that's not a digit [^0-9]\n",
    "Quantifier: *? Between zero and unlimited times, as few times as possible, expanding as needed [lazy]\n",
    "\\s* match any white space character [\\r\\n\\t\\f ]\n",
    "Quantifier: * Between zero and unlimited times, as many times as possible, giving back as needed [greedy]\n",
    "\n",
    "2nd Capturing group (\\d+)\n",
    "\\d+ match a digit [0-9]\n",
    "Quantifier: + Between one and unlimited times, as many times as possible, giving back as needed [greedy]\n",
    "2nd Alternative: (\\S.*)\n",
    "\n",
    "3rd Capturing group (\\S.*)\n",
    "\\S match any non-white space character [^\\r\\n\\t\\f ]\n",
    ".* matches any character (except newline)\n",
    "Quantifier: * Between zero and unlimited times, as many times as possible, giving back as needed [greedy]\n",
    "\n",
    "```\n",
    "\n",
    "![I know regular expressions](https://imgs.xkcd.com/comics/regular_expressions.png)\n",
    "\n",
    "\n",
    "\n",
    "Wow, that's very hard to understand. \n",
    "\n",
    "But now we have our address normalized and separated on its components. We can now try to match it with the canonical source. \n",
    "\n",
    "## Match\n",
    "\n",
    "The previous steps did not correct for misspellings or other errors. If we have a canonical database, we can try to reduce those errors and transform our address in our database to a canonical form. For that, we have to *match* the normalized address with our reference database. First, how we calculate that two addresses are similar?\n",
    "\n",
    "### Similarity\n",
    "We can compute a [similarity](https://en.wikipedia.org/wiki/String_metric) between two strings. There are several algorithms to do that. We will use the [Jaro-Winkler](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance) distance for that. There are several others, like \n",
    "\n",
    "- [Cosine Distance](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
    "- [Hamming Distance](https://en.wikipedia.org/wiki/Hamming_distance)\n",
    "\n",
    "### Candidates for match\n",
    "\n",
    "How can we retrieve candidates to match from our canonical database?\n",
    "\n",
    "There are a few approaches:\n",
    "\n",
    "- Brute force (all against all)\n",
    "- Search by field\n",
    "\n",
    "We will try to search for candidates and do a match with them.\n",
    "\n",
    "## Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 12]\n",
      "[{'street': 'XV de novembro', 'complement': 'bloco 22', 'city': 'São Paulo', 'number': 123, 'cep': '02837-223'}, {'street': 'XV de novembro', 'complement': 'bloco 23 A', 'city': 'São Paulo', 'number': 123, 'cep': '02837-223'}]\n"
     ]
    }
   ],
   "source": [
    "schema = create_schema()\n",
    "idx = create_index(schema, 'indexdir')\n",
    "results = search(parsed_address['street'], 'street', idx)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have our candidates! But the other informations are different from what whe have in our address. Is this a match?\n",
    "\n",
    "## Match\n",
    "\n",
    "Let's devise a way to match these two addresses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rua XV de Novembro, 123 bloco 23 A\n"
     ]
    }
   ],
   "source": [
    "print(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have some prior information about how addresses are and which parts are more important than others. We can devise a matching algorithm with a linear regression, for example, using the knowledge that street names are more important than complements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7462722462722463"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(parsed_address['street'],results[0]['street'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7462722462722463"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(parsed_address['street'],results[1]['street'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the similarity of the street name is exactly the same. Let's compare the numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888888888888888"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(str(parsed_address['number']),str(results[0]['number'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6888888888888888"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(str(parsed_address['number']),str(results[1]['number'] ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ops, still the same. Let's go to complements:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(parsed_address['complement'],results[0]['complement'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(parsed_address['complement'],results[1]['complement'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, there's a small difference, but we will assume that we can work with that! The second canonical address is a better match than the first one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Address: Rua XV de Novembro, 123 bloco 23 A\n",
      "Canonical Address: XV de novembro, 123 bloco 23 A\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Address:\", address)\n",
    "print(\"Canonical Address:\", str(results[1]['street']) + ', ' + str(results[1]['number']) + ' ' + str(results[1]['complement']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
